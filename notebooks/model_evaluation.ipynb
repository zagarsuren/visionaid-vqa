{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5246e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zagaraa/Documents/GitHub/visionaid-vqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d066bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md         \u001b[34massets\u001b[m\u001b[m/           \u001b[34mnotebooks\u001b[m\u001b[m/        \u001b[34mvqa\u001b[m\u001b[m/\n",
      "app.py            \u001b[34mdata\u001b[m\u001b[m/             \u001b[34moutputs\u001b[m\u001b[m/\n",
      "app2.py           \u001b[34mmodels\u001b[m\u001b[m/           requirements.txt\n",
      "appstt.py         \u001b[34mmodules\u001b[m\u001b[m/          \u001b[34mscripts\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded2ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "\n",
      "‚úÖ Overall Test Accuracy: 0.1638\n",
      "\n",
      "üîç Accuracy by Answer Type:\n",
      "         yes/no: 0.6333 (30 samples)\n",
      "         number: 0.1667 (6 samples)\n",
      "          other: 0.4000 (115 samples)\n",
      "   unanswerable: 0.0000 (252 samples)\n",
      "\n",
      "üß† Average BLEU-1 Score: 0.1638\n"
     ]
    }
   ],
   "source": [
    "!python scripts/evaluate_vilt.py \\\n",
    "  --test_image_dir /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset/test \\\n",
    "  --test_annotations /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset/annotations/test.json \\\n",
    "  --model_path /Users/zagaraa/Documents/GitHub/visionaid-vqa/models/vilt_finetuned_vizwiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c05426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "\n",
      "‚úÖ Overall Test Accuracy: 0.1464\n",
      "\n",
      "üîç Accuracy by Answer Type:\n",
      "         yes/no: 0.5000 (30 samples)\n",
      "         number: 0.3333 (6 samples)\n",
      "          other: 0.3652 (115 samples)\n",
      "   unanswerable: 0.0000 (252 samples)\n",
      "\n",
      "üß† Average BLEU-1 Score: 0.1473\n"
     ]
    }
   ],
   "source": [
    "!python scripts/evaluate_vilt.py \\\n",
    "  --test_image_dir /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset/test \\\n",
    "  --test_annotations /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset/annotations/test.json \\\n",
    "  --model_path /Users/zagaraa/Documents/GitHub/visionaid-vqa/models/vilt_finetuned_vizwiz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401a18b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "\n",
      "‚úÖ Overall Test Accuracy: 0.3880\n",
      "\n",
      "üîç Accuracy by Answer Type:\n",
      "         yes/no: 0.6667 (129 samples)\n",
      "         number: 0.1081 (37 samples)\n",
      "          other: 0.3881 (134 samples)\n",
      "   unanswerable: 0.0000 (66 samples)\n",
      "\n",
      "üß† Average BLEU-1 Score: 0.3938\n"
     ]
    }
   ],
   "source": [
    "!python scripts/evaluate_vilt.py \\\n",
    "  --test_image_dir /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset2/test \\\n",
    "  --test_annotations /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset2/annotations/test.json \\\n",
    "  --model_path /Users/zagaraa/Documents/GitHub/visionaid-vqa/models/vilt_finetuned_vizwiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9e50be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "\n",
      "‚úÖ Overall Test Accuracy: 0.3689\n",
      "\n",
      "üîç Accuracy by Answer Type:\n",
      "         yes/no: 0.6667 (129 samples)\n",
      "         number: 0.0811 (37 samples)\n",
      "          other: 0.3433 (134 samples)\n",
      "   unanswerable: 0.0000 (66 samples)\n",
      "\n",
      "üß† Average BLEU-1 Score: 0.3742\n"
     ]
    }
   ],
   "source": [
    "!python scripts/evaluate_vilt.py \\\n",
    "  --test_image_dir /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset2/test \\\n",
    "  --test_annotations /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset2/annotations/test.json \\\n",
    "  --model_path /Users/zagaraa/Documents/GitHub/visionaid-vqa/models/vilt_finetuned_vizwiz_ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d6a0d",
   "metadata": {},
   "source": [
    "# Florence-2 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d602fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zagaraa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "\n",
      "Evaluating the Florence2 model on the test set...\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/scripts/evaluate_florence2.py\", line 178, in <module>\n",
      "    main()\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/scripts/evaluate_florence2.py\", line 134, in main\n",
      "    generated_ids = model.generate(\n",
      "  File \"/Users/zagaraa/.cache/huggingface/modules/transformers_modules/microsoft/Florence-2-base-ft/9803f52844ec1ae5df004e6089262e9a23e527fd/modeling_florence2.py\", line 2796, in generate\n",
      "    return self.language_model.generate(\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/transformers/generation/utils.py\", line 2067, in generate\n",
      "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/transformers/generation/utils.py\", line 652, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/zagaraa/.cache/huggingface/modules/transformers_modules/microsoft/Florence-2-base-ft/9803f52844ec1ae5df004e6089262e9a23e527fd/modeling_florence2.py\", line 1578, in forward\n",
      "    embed_pos = self.embed_positions(input)\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/zagaraa/.cache/huggingface/modules/transformers_modules/microsoft/Florence-2-base-ft/9803f52844ec1ae5df004e6089262e9a23e527fd/modeling_florence2.py\", line 736, in forward\n",
      "    return super().forward(positions + self.offset)\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/nn/modules/sparse.py\", line 163, in forward\n",
      "    return F.embedding(\n",
      "  File \"/Users/zagaraa/Documents/GitHub/visionaid-vqa/vqa/lib/python3.9/site-packages/torch/nn/functional.py\", line 2237, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "IndexError: index out of range in self\n"
     ]
    }
   ],
   "source": [
    "!python scripts/evaluate_florence2.py \\\n",
    "  --test_image_dir /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset2/test \\\n",
    "  --test_annotations /Users/zagaraa/Documents/GitHub/visionaid-vqa/data/balanced_subset2/annotations/test.json \\\n",
    "  --model_path /Users/zagaraa/Documents/GitHub/visionaid-vqa/models/florence2-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd0dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
